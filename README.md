
# ğŸš€ SHL Assessment Recommendation System (GenAI)

An intelligent **LLM-powered recommendation system** that helps hiring managers and recruiters find the most relevant **SHL Individual Test Solutions** using natural language queries, job descriptions, or job description URLs.

This project was built as part of the **SHL GenAI Take-Home Assessment** and demonstrates strong problem-solving, context engineering, and GenAI-based retrieval skills.

---

## ğŸ“Œ Table of Contents
- [Problem Overview](#problem-overview)
- [Solution Overview](#solution-overview)
- [System Architecture](#system-architecture)
- [Workflow Diagram](#workflow-diagram)
- [Data Pipeline](#data-pipeline)
- [Technology Stack](#technology-stack)
- [API Design](#api-design)
- [Evaluation Strategy](#evaluation-strategy)
- [Performance Metric](#performance-metric)
- [Submission Artifacts](#submission-artifacts)
- [How to Run Locally](#how-to-run-locally)
- [Future Improvements](#future-improvements)

---

## ğŸ§  Problem Overview

Recruiters often struggle to identify the right assessments for a given role using keyword-based filters.  
The goal of this project is to **replace keyword search with semantic understanding** using GenAI and embeddings.

**Input:**  
- Natural language query  
- Job description text  
- URL containing a job description  

**Output:**  
- 5â€“10 relevant **SHL Individual Test Solutions**
- Each result includes:
  - Assessment Name
  - Official SHL URL

> âš ï¸ *Pre-packaged Job Solutions are explicitly excluded*

---

## ğŸ’¡ Solution Overview

This system uses a **Retrieval-Augmented Generation (RAG)** style pipeline:
1. Crawl SHL assessment catalog (â‰¥377 individual tests)
2. Convert assessment metadata into semantic embeddings
3. Store embeddings in a FAISS vector database
4. Retrieve relevant assessments using similarity search
5. Balance technical and behavioral assessments
6. Evaluate results using **Mean Recall@10**

---

## ğŸ—ï¸ System Architecture

**High-level components:**
- Web Scraper
- Data Cleaner & Normalizer
- Embedding Generator
- Vector Store (FAISS)
- Recommendation Engine
- REST API
- Evaluation Pipeline

---

## ğŸ”„ Workflow Diagram

```mermaid
flowchart TD
    A[SHL Product Catalog] --> B[Web Scraper]
    B --> C[Clean & Normalize Data]
    C --> D[Text for Embeddings]
    D --> E[Embedding Model]
    E --> F[FAISS Vector Store]

    G[User Query / JD / URL] --> H[Query Embedding]
    H --> F
    F --> I[Top-K Retrieval]
    I --> J[Balancing Logic]
    J --> K[Final Recommendations]
```

---

## ğŸ“Š Data Pipeline

1. **Scraping**
   - Crawled SHL product catalog
   - Ensured â‰¥377 Individual Test Solutions

2. **Data Structuring**
   - Fields:
     - id
     - name
     - url
     - test_type
     - remote_testing
     - adaptive_irt
     - text_for_embedding

3. **Embedding Creation**
   - Rich natural language description generated per assessment
   - Stored in FAISS for efficient similarity search

---

## ğŸ› ï¸ Technology Stack

- **Python 3.10+**
- **FastAPI** â€“ REST API
- **FAISS** â€“ Vector database
- **LLM Embeddings** (Gemini / HuggingFace)
- **Pandas & NumPy** â€“ Data processing
- **LangChain** â€“ Retrieval orchestration
- **Mermaid** â€“ Architecture visualization

---

## ğŸŒ API Design

### 1ï¸âƒ£ Health Check
```
GET /health
```
**Response**
```json
{
  "status": "ok"
}
```

---

### 2ï¸âƒ£ Assessment Recommendation
```
POST /recommend
```

**Request**
```json
{
  "query": "Looking for a Java developer with strong collaboration skills"
}
```

**Response**
```json
{
  "recommendations": [
    {
      "assessment_name": "Java Programming Test",
      "assessment_url": "https://www.shl.com/..."
    }
  ]
}
```

âœ”ï¸ Returns **1â€“10 results**  
âœ”ï¸ JSON-only responses  
âœ”ï¸ HTTP status codes respected  

---

## ğŸ“ˆ Evaluation Strategy

Evaluation was performed using:
- Provided **labeled train dataset**
- Iterative prompt and embedding tuning
- Retrieval-focused evaluation (not generation-only)

### Improvements Applied:
- Enhanced `text_for_embedding`
- Reduced noise in assessment descriptions
- Balanced hard vs soft skill recommendations

---

## ğŸ“ Performance Metric

### Mean Recall@K

Measures how many **relevant assessments** appear in the **top-K** results.

```
Recall@K = (Relevant items in Top K) / (Total relevant items)

Mean Recall@K = Average Recall@K across all queries
```

This project optimizes **Mean Recall@10** as required.

---

## ğŸ“¦ Submission Artifacts

âœ”ï¸ **API Endpoint URL**  
âœ”ï¸ **GitHub Repository (complete code + experiments)**  
âœ”ï¸ **Web Application URL**  
âœ”ï¸ **2-page Approach Document**  
âœ”ï¸ **Predictions CSV**
```
Query,Assessment_url
```

âœ”ï¸ Output format strictly follows **Appendix 3**

---

## â–¶ï¸ How to Run Locally

```bash
git clone <repo-url>
cd Recommendation_System
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
python main.py
```

API available at:
```
http://localhost:8000
```

---

## ğŸ”® Future Improvements

- Hybrid keyword + semantic retrieval
- Cross-encoder reranking
- Better JD URL parsing
- Multilingual query support
- Online learning from recruiter feedback

---

## ğŸ™Œ Final Notes

This project demonstrates:
- Strong **GenAI system design**
- Clean, modular, and testable code
- Clear evaluation methodology
- Practical application of LLMs beyond prompt engineering

Thank you for reviewing this submission!
