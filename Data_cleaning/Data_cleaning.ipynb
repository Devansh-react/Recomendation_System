{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7c69854",
   "metadata": {},
   "source": [
    "Data Cleaning and preparation completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba9bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"id\": \"global_skills_development_report\",\n",
    "  \"name\": \"Global Skills Development Report\",\n",
    "  \"url\": \"https://www.shl.com/products/product-catalog/view/global-skills-development-report/\",\n",
    "  \"test_type\": [\n",
    "    \"Aptitude\",\n",
    "    \"Behavioral\",\n",
    "    \"Cognitive\",\n",
    "    \"Development\",\n",
    "    \"English\",\n",
    "    \"Personality & Behavior\"\n",
    "  ],\n",
    "  \"text_for_embedding\": \"Assessment name: Global Skills Development Report. Assessment types: Aptitude, Behavioral, Cognitive, Development, English, Personality & Behavior. Used for hiring and evaluating candidates based on skills, abilities, and behavior.\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e4a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0a3e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('Raw_data.json')\n",
    "df= pd.DataFrame(data)\n",
    "df.head()\n",
    "df[\"test_type\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e63fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_TYPE_MAP = {\n",
    "    \"A\": \"Aptitude\",\n",
    "    \"B\": \"Behavioral\",\n",
    "    \"C\": \"Cognitive\",\n",
    "    \"D\": \"Development\",\n",
    "    \"E\": \"English\",\n",
    "    \"F\": \"Functional\",\n",
    "    \"K\": \"Knowledge & Skills\",\n",
    "    \"P\": \"Personality & Behavior\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411069b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_TYPE_MAP = {\n",
    "    \"A\": \"Aptitude\",\n",
    "    \"B\": \"Behavioral\",\n",
    "    \"C\": \"Cognitive\",\n",
    "    \"D\": \"Development\",\n",
    "    \"E\": \"English\",\n",
    "    \"F\": \"Functional\",\n",
    "    \"K\": \"Knowledge & Skills\",\n",
    "    \"P\": \"Personality & Behavior\"\n",
    "}\n",
    "\n",
    "df[\"test_type\"] = df[\"test_type\"].apply(\n",
    "    lambda codes: [TEST_TYPE_MAP[c] for c in codes if c in TEST_TYPE_MAP]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8469470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_text_for_embedding(row):\n",
    "    test_types = \", \".join(row[\"test_type\"])\n",
    "    remote = \"supports remote testing\" if row[\"remote_testing\"] else \"does not require remote testing\"\n",
    "    adaptive = \"uses adaptive IRT methodology\" if row[\"adaptive_irt\"] else \"uses standard testing methodology\"\n",
    "\n",
    "    return (\n",
    "        f\"Assessment name: {row['name']}. \"\n",
    "        f\"Assessment types: {test_types}. \"\n",
    "        f\"This assessment {remote} and {adaptive}. \"\n",
    "        \"Used for hiring and candidate evaluation.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f384cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_for_embedding\"] = df.apply(build_text_for_embedding, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b16c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_for_embedding\"].head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c76ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"test_type\"].apply(len).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33528585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def generate_id(name):\n",
    "    name = name.lower()\n",
    "    name = re.sub(r\"[^a-z0-9\\s]\", \"\", name)\n",
    "    return re.sub(r\"\\s+\", \"_\", name)\n",
    "\n",
    "df[\"id\"] = df[\"name\"].apply(generate_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c239aa2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"id\"] = df[\"name\"].apply(generate_id)\n",
    "\n",
    "df = df[[\"id\"] + list(df.columns.drop(\"id\"))]\n",
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f5abd39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"final_assessments.json\", orient=\"records\", indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
